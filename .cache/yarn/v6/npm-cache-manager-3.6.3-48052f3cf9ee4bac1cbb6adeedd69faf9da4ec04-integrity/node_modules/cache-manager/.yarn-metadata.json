{
  "manifest": {
    "name": "cache-manager",
    "version": "3.6.3",
    "description": "Cache module for Node.js",
    "main": "index.js",
    "files": [
      "index.js",
      "/examples",
      "/lib"
    ],
    "scripts": {
      "test": "make"
    },
    "repository": {
      "type": "git",
      "url": "https://github.com/BryanDonovan/node-cache-manager.git"
    },
    "keywords": [
      "cache",
      "redis",
      "lru-cache",
      "memory cache",
      "multiple cache"
    ],
    "author": {
      "name": "Bryan Donovan"
    },
    "license": "MIT",
    "dependencies": {
      "async": "3.2.3",
      "lodash.clonedeep": "^4.5.0",
      "lru-cache": "6.0.0"
    },
    "devDependencies": {
      "coveralls": "3.1.0",
      "es6-promise": "^4.2.8",
      "eslint": "7.7.0",
      "jsdoc": "3.6.5",
      "mocha": "8.1.1",
      "nyc": "15.1.0",
      "optimist": "0.6.1",
      "sinon": "9.0.3"
    },
    "_registry": "npm",
    "_loc": "/home/dpcsdev/.cache/yarn/v6/npm-cache-manager-3.6.3-48052f3cf9ee4bac1cbb6adeedd69faf9da4ec04-integrity/node_modules/cache-manager/package.json",
    "readmeFilename": "README.md",
    "readme": "[![build status](https://secure.travis-ci.org/BryanDonovan/node-cache-manager.svg)](http://travis-ci.org/BryanDonovan/node-cache-manager)\n[![Coverage Status](https://coveralls.io/repos/BryanDonovan/node-cache-manager/badge.svg?branch=master)](https://coveralls.io/r/BryanDonovan/node-cache-manager?branch=master)\n\nnode-cache-manager\n======================\n\n# Flexible NodeJS cache module\n\nA cache module for nodejs that allows easy wrapping of functions in cache,\ntiered caches, and a consistent interface.\n\n## Features\n\n* Easy way to wrap any function in cache.\n* Tiered caches -- data gets stored in each cache and fetched from the highest\npriority cache(s) first.\n* Use any cache you want, as long as it has the same API.\n* 100% test coverage via [mocha](https://github.com/visionmedia/mocha),\n  [istanbul](https://github.com/yahoo/istanbul), and [sinon](http://sinonjs.org).\n\n\n## Express.js Example\n\nSee the [Express.js cache-manager example app](https://github.com/BryanDonovan/node-cache-manager-express-example) to see how to use\n``node-cache-manager`` in your applications.\n\n## Installation\n\n    npm install cache-manager\n\n## Store Engines\n* [node-cache-manager-redis](https://github.com/dial-once/node-cache-manager-redis) (uses [sol-redis-pool](https://github.com/joshuah/sol-redis-pool))\n\n* [node-cache-manager-redis-store](https://github.com/dabroek/node-cache-manager-redis-store) (uses [node_redis](https://github.com/NodeRedis/node_redis))\n\n* [node-cache-manager-ioredis](https://github.com/dabroek/node-cache-manager-ioredis) (uses [ioredis](https://github.com/luin/ioredis))\n\n* [node-cache-manager-mongodb](https://github.com/v4l3r10/node-cache-manager-mongodb)\n\n* [node-cache-manager-mongoose](https://github.com/disjunction/node-cache-manager-mongoose)\n\n* [node-cache-manager-fs-binary](https://github.com/sheershoff/node-cache-manager-fs-binary)\n\n* [node-cache-manager-fs-hash](https://github.com/rolandstarke/node-cache-manager-fs-hash)\n\n* [node-cache-manager-hazelcast](https://github.com/marudor/node-cache-manager-hazelcast)\n\n* [node-cache-manager-memcached-store](https://github.com/theogravity/node-cache-manager-memcached-store)\n\n* [node-cache-manager-memory-store](https://github.com/theogravity/node-cache-manager-memory-store)\n\n* [node-cache-manager-couchbase](https://github.com/davidepellegatta/node-cache-manager-couchbase)\n\n## Overview\n\n**First**, it includes a `wrap` function that lets you wrap any function in cache.\n(Note, this was inspired by [node-caching](https://github.com/mape/node-caching).)\nThis is probably the feature you're looking for.  As an example, where you might have to do this:\n\n```javascript\nfunction getCachedUser(id, cb) {\n    memoryCache.get(id, function (err, result) {\n        if (err) { return cb(err); }\n\n        if (result) {\n            return cb(null, result);\n        }\n\n        getUser(id, function (err, result) {\n            if (err) { return cb(err); }\n            memoryCache.set(id, result);\n            cb(null, result);\n        });\n    });\n}\n```\n... you can instead use the `wrap` function:\n\n```javascript\nfunction getCachedUser(id, cb) {\n    memoryCache.wrap(id, function (cacheCallback) {\n        getUser(id, cacheCallback);\n    }, {ttl: ttl}, cb);\n}\n```\n\n**Second**, node-cache-manager features a built-in memory cache (using [node-lru-cache](https://github.com/isaacs/node-lru-cache)),\nwith the standard functions you'd expect in most caches:\n\n    set(key, val, {ttl: ttl}, cb) // * see note below\n    get(key, cb)\n    del(key, cb)\n    mset(key1, val1, key2, val2, {ttl: ttl}, cb) // set several keys at once\n    mget(key1, key2, key3, cb) // get several keys at once\n\n    // * Note that depending on the underlying store, you may be able to pass the\n    // ttl as the third param, like this:\n    set(key, val, ttl, cb)\n    // ... or pass no ttl at all:\n    set(key, val, cb)\n\n**Third**, node-cache-manager lets you set up a tiered cache strategy.  This may be of\nlimited use in most cases, but imagine a scenario where you expect tons of\ntraffic, and don't want to hit your primary cache (like Redis) for every request.\nYou decide to store the most commonly-requested data in an in-memory cache,\nperhaps with a very short timeout and/or a small data size limit.  But you\nstill want to store the data in Redis for backup, and for the requests that\naren't as common as the ones you want to store in memory. This is something\nnode-cache-manager handles easily and transparently.\n\n\n**Fourth**, it allows you to get and set multiple keys at once for caching store that support it. This means that when getting muliple keys it will go through the different caches starting from the highest priority one (see multi store below) and merge the values it finds at each level.\n\n## Usage Examples\n\nSee examples below and in the examples directory.  See ``examples/redis_example`` for an example of how to implement a\nRedis cache store with connection pooling.\n\n### Single Store\n\n```javascript\nvar cacheManager = require('cache-manager');\nvar memoryCache = cacheManager.caching({store: 'memory', max: 100, ttl: 10/*seconds*/});\nvar ttl = 5;\n// Note: callback is optional in set() and del().\n// Note: memory cache clones values before setting them unless\n// shouldCloneBeforeSet is set to false\n\nmemoryCache.set('foo', 'bar', {ttl: ttl}, function(err) {\n    if (err) { throw err; }\n\n    memoryCache.get('foo', function(err, result) {\n        console.log(result);\n        // >> 'bar'\n        memoryCache.del('foo', function(err) {});\n    });\n});\n\nfunction getUser(id, cb) {\n    setTimeout(function () {\n        console.log(\"Returning user from slow database.\");\n        cb(null, {id: id, name: 'Bob'});\n    }, 100);\n}\n\nvar userId = 123;\nvar key = 'user_' + userId;\n\n// Note: ttl is optional in wrap()\nmemoryCache.wrap(key, function (cb) {\n    getUser(userId, cb);\n}, {ttl: ttl}, function (err, user) {\n    console.log(user);\n\n    // Second time fetches user from memoryCache\n    memoryCache.wrap(key, function (cb) {\n        getUser(userId, cb);\n    }, function (err, user) {\n        console.log(user);\n    });\n});\n\n// Outputs:\n// Returning user from slow database.\n// { id: 123, name: 'Bob' }\n// { id: 123, name: 'Bob' }\n```\n\nThe `ttl` can also be computed dynamically by passing in a function. E.g.,\n\n```javascript\nvar opts = {\n    ttl: function(user) {\n        if (user.id === 1) {\n            return 0.1;\n        } else {\n            return 0.5;\n        }\n    }\n};\n\nmemoryCache.wrap(key, function(cb) {\n    getUser(userId, cb);\n}, opts, function(err, user) {\n    console.log(user);\n}\n```\n\nYou can get several keys at once. Note that this will return whatever records it\nfinds in the cache and it is up to the user to check the results against the\nsupplied keys and make any calls to the underlying data store to fill in\nmissing records. In practice, this should not be much of a concern if you are\nonly using the `wrap` function to set these records in cache.\n\nSide note: Ideally the `wrap` function would get what it can from the cache and fill in\nthe missing records from the data store, but I can't think of a way to do this\nthat is generic to all situations.  Another option is to only return the data\nfrom the cache if all records are found, but this woul break multi-caching.\n\nSee unit tests in `caching.unit.js` for more information.\n\nExample:\n\n```js\n\nvar key1 = 'user_1';\nvar key2 = 'user_1';\n\nmemoryCache.wrap(key1, key2, function (cb) {\n    getManyUser([key1, key2], cb);\n}, function (err, users) {\n    console.log(users[0]);\n    console.log(users[1]);\n});\n```\n\n#### Example setting/getting several keys with mset() and mget()\n\n```js\nmemoryCache.mset('foo', 'bar', 'foo2', 'bar2', {ttl: ttl}, function(err) {\n    if (err) { throw err; }\n\n    memoryCache.mget('foo', 'foo2', function(err, result) {\n        console.log(result);\n        // >> ['bar', 'bar2']\n\n        // Delete keys with del() passing arguments...\n        memoryCache.del('foo', 'foo2', function(err) {});\n\n        // ...passing an Array of keys\n        memoryCache.del(['foo', 'foo2'], function(err) {});\n    });\n});\n\n```\n\n#### Example Using Promises\n\n```javascript\nmemoryCache.wrap(key, function() {\n    return getUserPromise(userId);\n})\n.then(function(user) {\n    console.log('User:', user);\n});\n```\n\nIf you are using a Node version that does not include native promises, you can\nspecify your promise dependency in the options passed to the cache module.\nE.g.,\n\n```javascript\n\nvar Promise = require('es6-promise').Promise;\ncache = caching({store: store, promiseDependency: Promise});\n\n```\n\n#### Example Using async/await\n\n```javascript\n\ntry {\n  let user = await memoryCache.wrap(key, function() {\n    return getUserPromise(userId);\n  });\n} catch (err) {\n  // error handling\n}\n```\n\nHint: should wrap `await` call with `try` - `catch` to handle `promise` error.\n\n\n#### Example Express App Usage\n\n(Also see the [Express.js cache-manager example app](https://github.com/BryanDonovan/node-cache-manager-express-example)).\n\n```javascript\nfunction respond(res, err, data) {\n    if (err) {\n        res.json(500, err);\n    } else {\n        res.json(200, data);\n    }\n}\n\napp.get('/foo/bar', function(req, res) {\n    var cacheKey = 'foo-bar:' + JSON.stringify(req.query);\n    var ttl = 10;\n    memoryCache.wrap(cacheKey, function(cacheCallback) {\n        DB.find(req.query, cacheCallback);\n    }, {ttl: ttl}, function(err, result) {\n        respond(res, err, result);\n    });\n});\n```\n\n#### Custom Stores\n\nYou can use your own custom store by creating one with the same API as the\nbuilt-in memory stores (such as a redis or memcached store).  To use your own store just pass\nin an instance of it.\n\nE.g.,\n\n```javascript\nvar myStore = require('your-homemade-store');\nvar cache = cacheManager.caching({store: myStore});\n```\n\n### Multi-Store\n\n```javascript\nvar multiCache = cacheManager.multiCaching([memoryCache, someOtherCache]);\nuserId2 = 456;\nkey2 = 'user_' + userId;\nttl = 5;\n\n// Sets in all caches.\n// The \"ttl\" option can also be a function (see example below)\nmultiCache.set('foo2', 'bar2', {ttl: ttl}, function(err) {\n    if (err) { throw err; }\n\n    // Fetches from highest priority cache that has the key.\n    multiCache.get('foo2', function(err, result) {\n        console.log(result);\n        // >> 'bar2'\n\n        // Delete from all caches\n        multiCache.del('foo2');\n    });\n});\n\n// Set the ttl value by context depending on the store.\nfunction getTTL(data, store) {\n    if (store === 'redis') {\n        return 6000;\n    }\n    return 3000;\n}\n\n// Sets multiple keys in all caches.\n// You can pass as many key,value pair as you want\nmultiCache.mset('key', 'value', 'key2', 'value2', {ttl: getTTL}, function(err) {\n    if (err) { throw err; }\n\n    // mget() fetches from highest priority cache.\n    // If the first cache does not return all the keys,\n    // the next cache is fetched with the keys that were not found.\n    // This is done recursively until either:\n    // - all have been found\n    // - all caches has been fetched\n    multiCache.mget('key', 'key2', function(err, result) {\n        console.log(result[0]);\n        console.log(result[1]);\n        // >> 'bar2'\n        // >> 'bar3'\n\n        // Delete from all caches\n        multiCache.del('key', 'key2');\n        // ...or with an Array\n        multiCache.del(['key', 'key2']);\n    });\n});\n\n// Note: options with ttl are optional in wrap()\nmultiCache.wrap(key2, function (cb) {\n    getUser(userId2, cb);\n}, {ttl: ttl}, function (err, user) {\n    console.log(user);\n\n    // Second time fetches user from memoryCache, since it's highest priority.\n    // If the data expires in the memory cache, the next fetch would pull it from\n    // the 'someOtherCache', and set the data in memory again.\n    multiCache.wrap(key2, function (cb) {\n        getUser(userId2, cb);\n    }, function (err, user) {\n        console.log(user);\n    });\n});\n\n// Multiple keys\nmultiCache.wrap('key1', 'key2', function (cb) {\n    getManyUser(['key1', 'key2'], cb);\n}, {ttl: ttl}, function (err, users) {\n    console.log(users[0]);\n    console.log(users[1]);\n});\n```\n\n### Specifying What to Cache in `wrap` Function\n\nBoth the `caching` and `multicaching` modules allow you to pass in a callback function named\n`isCacheableValue` which is called by the `wrap` function with every value returned from cache or from the wrapped function.\nThis lets you specify which values should and should not be cached by `wrap`. If the function returns true, it will be\nstored in cache. By default the caches cache everything except `undefined`.\n\nNOTE: The `set` functions in `caching` and `multicaching` do *not* use `isCacheableValue`.\n\nFor example, if you don't want to cache `false` and `null`, you can pass in a function like this:\n\n```javascript\n\nvar isCacheableValue = function(value) {\n    return value !== null && value !== false && value !== undefined;\n};\n\n```\n\nThen pass it to `caching` like this:\n\n```javascript\n\nvar memoryCache = cacheManager.caching({store: 'memory', isCacheableValue: isCacheableValue});\n\n```\n\nAnd pass it to `multicaching` like this:\n\n```javascript\n\nvar multiCache = cacheManager.multiCaching([memoryCache, someOtherCache], {\n    isCacheableValue: isCacheableValue\n});\n\n```\n\n### Refresh cache keys in background\n\nBoth the `caching` and `multicaching` modules support a mechanism to refresh expiring cache keys in background when using `wrap` function.\nThis is done by adding a `refreshThreshold` attribute while creating the caching store.\n\nIf `refreshThreshold` is set and if the `ttl` method is available for the used store, after retrieving a value from cache TTL will be checked.\nIf the remaining TTL is less than `refreshThreshold`, the system will spawn a background worker to update the value, following same rules as standard fetching. In the meantime, the system will return the old value until expiration.\n\nIn case of multicaching, the store that will be used for refresh is the one where the key will be found first (highest priority). The value will then be set in all the stores.\n\nNOTES:\n\n* In case of multicaching, the store that will be checked for refresh is the one where the key will be found first (highest priority).\n* If the threshold is low and the worker function is slow, the key may expire and you may encounter a racing condition with updating values.\n* The background refresh mechanism currently does not support providing multiple keys to `wrap`Â function.\n* The caching store needs to provide the `ttl` method.\n\nFor example, pass the refreshThreshold to `caching` like this:\n\n```javascript\nvar redisStore = require('cache-manager-ioredis');\n\nvar redisCache = cacheManager.caching({store: redisStore, refreshThreshold: 3, isCacheableValue: isCacheableValue});\n```\n\nWhen a value will be retrieved from Redis with a remaining TTL < 3sec, the value will be updated in background.\n\n### Development environment\nYou may disable real caching but still get all the callback functionality working by setting `none` store.\n\n## Docs\n\nTo generate JSDOC 3 documentation:\n\n    make docs\n\n## Tests\n\nTo run tests, first run:\n\n    npm install -d\n\nRun the tests and JShint:\n\n    make\n\n\n## Contribute\n\nIf you would like to contribute to the project, please fork it and send us a pull request.  Please add tests\nfor any new features or bug fixes.  Also run `make` before submitting the pull request.\n\n\n## License\n\nnode-cache-manager is licensed under the MIT license.\n",
    "licenseText": "Copyrights for code authored by MOG Inc. is licensed under the following terms:\n\nMIT License\n\nCopyright (c) 2011 MOG Inc. All Rights Reserved.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to\ndeal in the Software without restriction, including without limitation the\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\nsell copies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\nDEALINGS IN THE SOFTWARE.\n"
  },
  "artifacts": [],
  "remote": {
    "resolved": "https://registry.yarnpkg.com/cache-manager/-/cache-manager-3.6.3.tgz#48052f3cf9ee4bac1cbb6adeedd69faf9da4ec04",
    "type": "tarball",
    "reference": "https://registry.yarnpkg.com/cache-manager/-/cache-manager-3.6.3.tgz",
    "hash": "48052f3cf9ee4bac1cbb6adeedd69faf9da4ec04",
    "integrity": "sha512-dS4DnV6c6cQcVH5OxzIU1XZaACXwvVIiUPkFytnRmLOACuBGv3GQgRQ1RJGRRw4/9DF14ZK2RFlZu1TUgDniMg==",
    "registry": "npm",
    "packageName": "cache-manager",
    "cacheIntegrity": "sha512-dS4DnV6c6cQcVH5OxzIU1XZaACXwvVIiUPkFytnRmLOACuBGv3GQgRQ1RJGRRw4/9DF14ZK2RFlZu1TUgDniMg== sha1-SAUvPPnuS6wcu2re7dafr52k7AQ="
  },
  "registry": "npm",
  "hash": "48052f3cf9ee4bac1cbb6adeedd69faf9da4ec04"
}